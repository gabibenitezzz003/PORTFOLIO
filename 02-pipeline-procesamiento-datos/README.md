# Pipeline de Procesamiento de Datos con Pandas

## ğŸ“‹ DescripciÃ³n

Sistema completo de procesamiento y anÃ¡lisis de datos empresariales desarrollado con **Pandas**, **NumPy** y **Matplotlib**. Implementa un pipeline ETL robusto con anÃ¡lisis estadÃ­stico avanzado, visualizaciones interactivas y reportes automatizados.

## ğŸ—ï¸ Arquitectura del Pipeline

### PatrÃ³n Pipeline ETL
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EXTRACT (ExtracciÃ³n)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Fuentes CSV   â”‚  â”‚   APIs REST     â”‚  â”‚   Bases de  â”‚  â”‚
â”‚  â”‚   Excel, JSON   â”‚  â”‚   Web Scraping  â”‚  â”‚   Datos     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   TRANSFORM (TransformaciÃ³n)               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Limpieza de   â”‚  â”‚   AnÃ¡lisis      â”‚  â”‚   Feature   â”‚  â”‚
â”‚  â”‚   Datos         â”‚  â”‚   EstadÃ­stico   â”‚  â”‚   Engineeringâ”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     LOAD (Carga)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Base de Datos â”‚  â”‚   Archivos      â”‚  â”‚   Reportes  â”‚  â”‚
â”‚  â”‚   PostgreSQL    â”‚  â”‚   CSV, Excel    â”‚  â”‚   PDF, HTML â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ CaracterÃ­sticas

- **Pipeline ETL** modular y escalable
- **AnÃ¡lisis estadÃ­stico** avanzado con Pandas y NumPy
- **Visualizaciones interactivas** con Matplotlib y Seaborn
- **Limpieza de datos** automatizada
- **Feature Engineering** inteligente
- **Reportes automatizados** en PDF y HTML
- **MÃ©tricas de calidad** de datos
- **ValidaciÃ³n de datos** robusta
- **Logging estructurado** del pipeline

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Pandas** - ManipulaciÃ³n y anÃ¡lisis de datos
- **NumPy** - CÃ¡lculos numÃ©ricos y arrays
- **Matplotlib** - Visualizaciones bÃ¡sicas
- **Seaborn** - Visualizaciones estadÃ­sticas
- **Plotly** - Visualizaciones interactivas
- **Scikit-learn** - Machine learning y mÃ©tricas
- **SQLAlchemy** - ConexiÃ³n a base de datos
- **Jinja2** - Templates para reportes
- **Docker** - ContainerizaciÃ³n

## ğŸ“ Estructura del Proyecto

```
02-pipeline-procesamiento-datos/
â”œâ”€â”€ datos/                        # Datos de entrada y salida
â”‚   â”œâ”€â”€ entrada/                  # Datos de entrada
â”‚   â”œâ”€â”€ procesados/               # Datos procesados
â”‚   â””â”€â”€ reportes/                 # Reportes generados
â”œâ”€â”€ pipeline/                     # CÃ³digo del pipeline
â”‚   â”œâ”€â”€ extractores/              # Extractores de datos
â”‚   â”œâ”€â”€ transformadores/          # Transformadores de datos
â”‚   â”œâ”€â”€ cargadores/               # Cargadores de datos
â”‚   â””â”€â”€ validadores/              # Validadores de datos
â”œâ”€â”€ analisis/                     # AnÃ¡lisis de datos
â”‚   â”œâ”€â”€ estadistico/              # AnÃ¡lisis estadÃ­stico
â”‚   â”œâ”€â”€ visualizaciones/          # GeneraciÃ³n de grÃ¡ficos
â”‚   â””â”€â”€ reportes/                 # GeneraciÃ³n de reportes
â”œâ”€â”€ utilidades/                   # Utilidades compartidas
â”‚   â”œâ”€â”€ decoradores/              # Decoradores personalizados
â”‚   â”œâ”€â”€ helpers/                  # Funciones auxiliares
â”‚   â””â”€â”€ configuracion/            # ConfiguraciÃ³n
â”œâ”€â”€ tests/                        # Tests automatizados
â”œâ”€â”€ notebooks/                    # Jupyter notebooks
â”œâ”€â”€ requirements.txt              # Dependencias
â”œâ”€â”€ Dockerfile                    # Imagen Docker
â”œâ”€â”€ docker-compose.yml            # OrquestaciÃ³n
â””â”€â”€ README.md                     # DocumentaciÃ³n
```

## ğŸš€ InstalaciÃ³n y Uso

### OpciÃ³n 1: Con Docker (Recomendado)

```bash
# Clonar el repositorio
git clone <repo-url>
cd 02-pipeline-procesamiento-datos

# Levantar servicios con Docker Compose
docker-compose up -d

# Ejecutar pipeline
docker-compose exec pipeline python -m pipeline.ejecutor
```

### OpciÃ³n 2: InstalaciÃ³n Local

```bash
# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Ejecutar pipeline
python -m pipeline.ejecutor
```

## ğŸ“Š Funcionalidades del Pipeline

### 1. ExtracciÃ³n de Datos
- **CSV/Excel:** Lectura de archivos planos
- **APIs REST:** ExtracciÃ³n de datos de APIs
- **Base de Datos:** Consultas SQL complejas
- **Web Scraping:** ExtracciÃ³n de datos web

### 2. TransformaciÃ³n de Datos
- **Limpieza:** Manejo de valores nulos y outliers
- **NormalizaciÃ³n:** EstandarizaciÃ³n de formatos
- **Feature Engineering:** CreaciÃ³n de nuevas variables
- **Agregaciones:** CÃ¡lculos estadÃ­sticos

### 3. AnÃ¡lisis EstadÃ­stico
- **EstadÃ­sticas Descriptivas:** Media, mediana, desviaciÃ³n
- **AnÃ¡lisis de CorrelaciÃ³n:** Matrices de correlaciÃ³n
- **AnÃ¡lisis de Tendencias:** Series temporales
- **AnÃ¡lisis de DistribuciÃ³n:** Histogramas y boxplots

### 4. Visualizaciones
- **GrÃ¡ficos de Barras:** Comparaciones categÃ³ricas
- **GrÃ¡ficos de LÃ­neas:** Tendencias temporales
- **Scatter Plots:** Relaciones entre variables
- **Heatmaps:** Matrices de correlaciÃ³n
- **Dashboards Interactivos:** Visualizaciones dinÃ¡micas

### 5. Reportes Automatizados
- **Reportes PDF:** Documentos profesionales
- **Reportes HTML:** Visualizaciones web
- **Dashboards:** Paneles interactivos
- **MÃ©tricas de Calidad:** Indicadores de datos

## ğŸ§ª Testing

```bash
# Ejecutar todos los tests
pytest

# Ejecutar con cobertura
pytest --cov=pipeline --cov=analisis

# Ejecutar tests especÃ­ficos
pytest tests/test_pipeline.py
```

## ğŸ“ˆ MÃ©tricas de Calidad

- **Cobertura de tests:** >90%
- **Tiempo de procesamiento:** <5 minutos para 1M registros
- **PrecisiÃ³n de datos:** >99.5%
- **Completitud de datos:** >95%
- **Consistencia de datos:** >98%

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno

```env
# Base de datos
DATABASE_URL=postgresql://usuario:password@localhost:5432/datos_empresa

# ConfiguraciÃ³n del pipeline
PIPELINE_BATCH_SIZE=10000
PIPELINE_MAX_WORKERS=4
PIPELINE_LOG_LEVEL=INFO

# ConfiguraciÃ³n de reportes
REPORT_OUTPUT_DIR=./datos/reportes
REPORT_FORMAT=pdf,html
```

## ğŸ“ Ejemplos de Uso

### AnÃ¡lisis de Ventas
```python
from pipeline.ejecutor import EjecutorPipeline
from analisis.estadistico import AnalizadorVentas

# Crear ejecutor
ejecutor = EjecutorPipeline()

# Ejecutar anÃ¡lisis de ventas
resultado = ejecutor.ejecutar_analisis_ventas(
    archivo_datos="ventas_2024.csv",
    generar_reporte=True
)
```

### AnÃ¡lisis de Texto
```python
from analisis.texto import AnalizadorTexto

# Crear analizador
analizador = AnalizadorTexto()

# Analizar sentimientos
resultado = analizador.analizar_sentimientos(
    texto="Este producto es excelente",
    idioma="es"
)
```

## ğŸš€ Despliegue

### Docker Hub
```bash
# Construir imagen
docker build -t pipeline-procesamiento-datos .

# Subir a Docker Hub
docker tag pipeline-procesamiento-datos username/pipeline-procesamiento-datos
docker push username/pipeline-procesamiento-datos
```

### ProducciÃ³n
```bash
# Usar docker-compose.prod.yml
docker-compose -f docker-compose.prod.yml up -d
```

## ğŸ¤ ContribuciÃ³n

1. Fork el proyecto
2. Crear rama feature (`git checkout -b feature/AnalisisIncreible`)
3. Commit cambios (`git commit -m 'Agregar AnalisisIncreible'`)
4. Push a la rama (`git push origin feature/AnalisisIncreible`)
5. Abrir Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

---

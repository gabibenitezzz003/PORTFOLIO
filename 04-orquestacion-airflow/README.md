# OrquestaciÃ³n de Workflows con Apache Airflow

## ğŸ“‹ DescripciÃ³n

Sistema completo de orquestaciÃ³n de workflows desarrollado con **Apache Airflow** para automatizar procesos de datos, ETL, anÃ¡lisis y machine learning. Implementa DAGs (Directed Acyclic Graphs) complejos, monitoreo en tiempo real, alertas inteligentes y escalabilidad horizontal.

## ğŸ—ï¸ Arquitectura del Sistema

### Arquitectura de OrquestaciÃ³n Airflow
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CAPA DE PRESENTACIÃ“N                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Web UI        â”‚  â”‚   API REST      â”‚  â”‚   CLI       â”‚  â”‚
â”‚  â”‚   (Monitoreo)   â”‚  â”‚   (IntegraciÃ³n) â”‚  â”‚   (Admin)   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CAPA DE ORQUESTACIÃ“N                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Scheduler     â”‚  â”‚   Executor      â”‚  â”‚   DAGs      â”‚  â”‚
â”‚  â”‚   (PlanificaciÃ³n)â”‚  â”‚   (EjecuciÃ³n)   â”‚  â”‚   (Workflows)â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CAPA DE TAREAS                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   ETL Tasks     â”‚  â”‚   ML Tasks      â”‚  â”‚   API Tasks â”‚  â”‚
â”‚  â”‚   (Datos)       â”‚  â”‚   (Modelos)     â”‚  â”‚   (Servicios)â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CAPA DE INFRAESTRUCTURA                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Base de Datos â”‚  â”‚   Almacenamientoâ”‚  â”‚   Servicios â”‚  â”‚
â”‚  â”‚   (PostgreSQL)  â”‚  â”‚   (S3/MinIO)    â”‚  â”‚   (Redis)   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ CaracterÃ­sticas

- **DAGs Complejos** con dependencias y paralelizaciÃ³n
- **Monitoreo en Tiempo Real** con mÃ©tricas y alertas
- **Escalabilidad Horizontal** con mÃºltiples workers
- **IntegraciÃ³n Completa** con APIs, bases de datos y servicios
- **Retry Inteligente** con backoff exponencial
- **Alertas AutomÃ¡ticas** por email, Slack y webhooks
- **Scheduling Avanzado** con cron y triggers
- **Logging Centralizado** con anÃ¡lisis de logs
- **Seguridad** con autenticaciÃ³n y autorizaciÃ³n
- **Backup y Recovery** automÃ¡tico

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Apache Airflow** - OrquestaciÃ³n de workflows
- **PostgreSQL** - Base de datos de metadatos
- **Redis** - Broker de mensajes y cachÃ©
- **Celery** - Ejecutor distribuido
- **Docker** - ContainerizaciÃ³n
- **Kubernetes** - OrquestaciÃ³n de contenedores (opcional)
- **Prometheus** - MÃ©tricas y monitoreo
- **Grafana** - Dashboards de visualizaciÃ³n
- **Python** - Lenguaje principal
- **SQLAlchemy** - ORM para base de datos

## ğŸ“ Estructura del Proyecto

```
04-orquestacion-airflow/
â”œâ”€â”€ dags/                        # DAGs de Airflow
â”‚   â”œâ”€â”€ etl/                    # DAGs de ETL
â”‚   â”œâ”€â”€ ml/                     # DAGs de Machine Learning
â”‚   â”œâ”€â”€ monitoreo/              # DAGs de monitoreo
â”‚   â””â”€â”€ utilidades/             # DAGs de utilidades
â”œâ”€â”€ plugins/                     # Plugins personalizados
â”‚   â”œâ”€â”€ operators/              # Operadores personalizados
â”‚   â”œâ”€â”€ sensors/                # Sensores personalizados
â”‚   â”œâ”€â”€ hooks/                  # Hooks personalizados
â”‚   â””â”€â”€ executors/              # Ejecutores personalizados
â”œâ”€â”€ config/                     # ConfiguraciÃ³n
â”‚   â”œâ”€â”€ airflow.cfg            # ConfiguraciÃ³n principal
â”‚   â”œâ”€â”€ logging.conf           # ConfiguraciÃ³n de logs
â”‚   â””â”€â”€ webserver_config.py    # ConfiguraciÃ³n web
â”œâ”€â”€ scripts/                    # Scripts de utilidad
â”‚   â”œâ”€â”€ init-db.py             # InicializaciÃ³n de BD
â”‚   â”œâ”€â”€ backup.py              # Backup de datos
â”‚   â””â”€â”€ monitoring.py          # Scripts de monitoreo
â”œâ”€â”€ tests/                      # Tests automatizados
â”‚   â”œâ”€â”€ unit/                  # Tests unitarios
â”‚   â”œâ”€â”€ integration/           # Tests de integraciÃ³n
â”‚   â””â”€â”€ e2e/                   # Tests end-to-end
â”œâ”€â”€ monitoring/                 # ConfiguraciÃ³n de monitoreo
â”‚   â”œâ”€â”€ prometheus/            # ConfiguraciÃ³n Prometheus
â”‚   â”œâ”€â”€ grafana/               # Dashboards Grafana
â”‚   â””â”€â”€ alerts/                # Reglas de alertas
â”œâ”€â”€ docker/                     # ConfiguraciÃ³n Docker
â”‚   â”œâ”€â”€ Dockerfile.airflow     # Imagen Airflow
â”‚   â”œâ”€â”€ Dockerfile.worker      # Imagen Worker
â”‚   â””â”€â”€ docker-compose.yml     # OrquestaciÃ³n
â”œâ”€â”€ k8s/                       # ConfiguraciÃ³n Kubernetes
â”‚   â”œâ”€â”€ namespace.yaml         # Namespace
â”‚   â”œâ”€â”€ configmap.yaml         # ConfigMap
â”‚   â”œâ”€â”€ secrets.yaml           # Secrets
â”‚   â””â”€â”€ deployments/           # Deployments
â”œâ”€â”€ requirements.txt            # Dependencias
â”œâ”€â”€ airflow.cfg                # ConfiguraciÃ³n Airflow
â””â”€â”€ README.md                  # DocumentaciÃ³n
```

## ğŸš€ InstalaciÃ³n y Uso

### OpciÃ³n 1: Con Docker Compose (Recomendado)

```bash
# Clonar el repositorio
git clone <repo-url>
cd 04-orquestacion-airflow

# Levantar servicios con Docker Compose
docker-compose up -d

# Verificar estado
docker-compose ps

# Acceder a la interfaz web
# http://localhost:8080 (admin/admin)
```

### OpciÃ³n 2: InstalaciÃ³n Local

```bash
# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Inicializar base de datos
airflow db init

# Crear usuario administrador
airflow users create \
    --username admin \
    --firstname Admin \
    --lastname User \
    --role Admin \
    --email admin@example.com

# Iniciar servicios
airflow webserver --port 8080 &
airflow scheduler &
```

### OpciÃ³n 3: Con Kubernetes

```bash
# Aplicar configuraciÃ³n de Kubernetes
kubectl apply -f k8s/

# Verificar pods
kubectl get pods -n airflow

# Acceder a la interfaz web
kubectl port-forward svc/airflow-webserver 8080:8080 -n airflow
```

## ğŸ“Š Funcionalidades del Sistema

### 1. DAGs de ETL
- **ExtracciÃ³n de Datos** de mÃºltiples fuentes
- **TransformaciÃ³n** con Pandas y SQL
- **Carga** a data warehouse
- **ValidaciÃ³n** de calidad de datos
- **Monitoreo** de rendimiento

### 2. DAGs de Machine Learning
- **Entrenamiento** de modelos
- **ValidaciÃ³n** y testing
- **Despliegue** de modelos
- **Monitoreo** de drift
- **Retraining** automÃ¡tico

### 3. DAGs de Monitoreo
- **Health Checks** de servicios
- **MÃ©tricas** de rendimiento
- **Alertas** automÃ¡ticas
- **Reportes** de estado
- **Dashboards** en tiempo real

### 4. DAGs de Utilidades
- **Backup** de datos
- **Limpieza** de logs
- **Mantenimiento** de BD
- **SincronizaciÃ³n** de configuraciones
- **AuditorÃ­a** de seguridad

## ğŸ§ª Testing

```bash
# Ejecutar todos los tests
pytest

# Ejecutar tests especÃ­ficos
pytest tests/unit/
pytest tests/integration/
pytest tests/e2e/

# Tests con cobertura
pytest --cov=dags --cov=plugins

# Tests de DAGs
python -m pytest tests/dag_tests.py
```

## ğŸ“ˆ Monitoreo y Alertas

### MÃ©tricas Disponibles
- **DAGs ejecutados** por dÃ­a/hora
- **Tiempo de ejecuciÃ³n** promedio
- **Tasa de Ã©xito/fallo** de tareas
- **Uso de recursos** (CPU, memoria)
- **Latencia** de tareas
- **Throughput** del sistema

### Alertas Configuradas
- **DAGs fallidos** por mÃ¡s de 1 hora
- **Tareas con error** repetido
- **Uso de recursos** alto
- **Conexiones** de BD perdidas
- **Espacio en disco** bajo

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno

```env
# Airflow
AIRFLOW_HOME=/opt/airflow
AIRFLOW__CORE__EXECUTOR=CeleryExecutor
AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql://user:pass@localhost:5432/airflow
AIRFLOW__CELERY__BROKER_URL=redis://localhost:6379/0
AIRFLOW__CELERY__RESULT_BACKEND=redis://localhost:6379/0

# Base de datos
POSTGRES_USER=airflow
POSTGRES_PASSWORD=airflow123
POSTGRES_DB=airflow

# Redis
REDIS_PASSWORD=redis123

# Monitoreo
PROMETHEUS_ENDPOINT=http://prometheus:9090
GRAFANA_ENDPOINT=http://grafana:3000
```

## ğŸ“ Ejemplos de DAGs

### DAG de ETL Diario
```python
from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator

default_args = {
    'owner': 'data-team',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5)
}

dag = DAG(
    'etl_diario',
    default_args=default_args,
    description='ETL diario de datos de ventas',
    schedule_interval='0 2 * * *',  # Diario a las 2 AM
    catchup=False
)

def extraer_datos():
    # LÃ³gica de extracciÃ³n
    pass

def transformar_datos():
    # LÃ³gica de transformaciÃ³n
    pass

def cargar_datos():
    # LÃ³gica de carga
    pass

# Definir tareas
extraer = PythonOperator(
    task_id='extraer_datos',
    python_callable=extraer_datos,
    dag=dag
)

transformar = PythonOperator(
    task_id='transformar_datos',
    python_callable=transformar_datos,
    dag=dag
)

cargar = PythonOperator(
    task_id='cargar_datos',
    python_callable=cargar_datos,
    dag=dag
)

# Definir dependencias
extraer >> transformar >> cargar
```

### DAG de Machine Learning
```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator

dag = DAG(
    'ml_pipeline',
    default_args=default_args,
    description='Pipeline de Machine Learning',
    schedule_interval='0 3 * * 0',  # Semanal los domingos
    catchup=False
)

def entrenar_modelo():
    # LÃ³gica de entrenamiento
    pass

def validar_modelo():
    # LÃ³gica de validaciÃ³n
    pass

def desplegar_modelo():
    # LÃ³gica de despliegue
    pass

# Tareas paralelas
entrenar = PythonOperator(
    task_id='entrenar_modelo',
    python_callable=entrenar_modelo,
    dag=dag
)

validar = PythonOperator(
    task_id='validar_modelo',
    python_callable=validar_modelo,
    dag=dag
)

desplegar = PythonOperator(
    task_id='desplegar_modelo',
    python_callable=desplegar_modelo,
    dag=dag
)

# Dependencias
entrenar >> validar >> desplegar
```

## ğŸš€ Despliegue

### Docker Hub
```bash
# Construir imagen
docker build -f docker/Dockerfile.airflow -t airflow-custom .

# Subir a Docker Hub
docker tag airflow-custom username/airflow-custom
docker push username/airflow-custom
```

### Kubernetes
```bash
# Aplicar configuraciÃ³n
kubectl apply -f k8s/

# Escalar workers
kubectl scale deployment airflow-worker --replicas=5 -n airflow

# Verificar estado
kubectl get all -n airflow
```

## ğŸ¤ ContribuciÃ³n

1. Fork el proyecto
2. Crear rama feature (`git checkout -b feature/DAGIncreible`)
3. Commit cambios (`git commit -m 'Agregar DAGIncreible'`)
4. Push a la rama (`git push origin feature/DAGIncreible`)
5. Abrir Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

